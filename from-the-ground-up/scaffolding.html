<!DOCTYPE html><html lang="en"><head><link rel="icon" href="data:,">
<script src="/common-script.js" type="text/javascript"></script></head>

<header>Scaffolding</header>
<address>
	Brian Haak
</address>

<section class="abstract">
<p>
Let's experiment with computation using the browser, and nothing else.
It's 2020, so we already can run almost low-level assembly instructions code in WebAssembly.
</p>
<p>
We have WebGL 1.0 consistently deployed in every device fully supporting GPU rendering API
called OpenGL ES 2.0.
</p>
<p>
And we have classes and destructuring in ES6, which is the best version of JavaScript web came up with.
</p>

<p>
Let's ignore cool kids' toolchains and frameworks: these cause trouble impeding simple explanations
of concepts. We're going to build everything literally from scratch.
</p>
</section>

<main>
<section><h1>Control: relay switch to reality simulator</h1>
<p>
Let's explore the concept of control.</p>

<p>
Control is the smallest computation step, it's a basic building block of computation.

Control is a trivial operation. A basic building block of control is a switch, or a valve.

Another word for "control" is "regulation".

The mysterious combination of the controlled outcomes ("results", "outputs") is often called "computation".
</p>
</section>

<section><h1>WebGL: controlling browser in space and time</h1>
<h2>Terminology</h2>
<p>GPU shader does this:<ol>
	<li>reads texture bits</li>
	<li>intertwines texture bits</li>
	<li>writes texture bits</li>
</ol>
There's literally no black magic beyond that.
</p>

<p>To avoid confusion between pixels, texels, and fragments, let's define these:</p>

<dl>
	<dt>Pixel</dt><dd>Visible on the screen <em>pic</em>ture <em>el</em>ement.</dd>
	<dt>Texel</dt><dd><em>Tex</em>ture <em>el</em>ement when shader <em>reads</em> it.</dd>
	<dt>Fragment</dt><dd>Pixel, texel, or an argument of resulting one when shader <em>writes</em>
		result of computation.
		Called "fragment" rather than "pixel" because one resulting pixel can be
		composed of more than one fragment in many runs, plus things like stencil and depth buffers
		influence what the result will be. It also can be <code>discard</code>'ed: no write will happen.</dd>
	<dt>Texture image unit</dt><dd>An array of texels available for one shader run.
		All GPUs support 8 simultaneous texture image units.
		Some systems can have 16, or 32.</dd>
	<dt>Color buffer</dt><dd>An array of pixels into which shader writes.
		Most mobile platforms have only one color buffer,
		and it's typically 32 bits per pixel wide.</dd>
</dl>

<p>The multiplicity of all texture image units, all texture sizes,
and the number of bits per texel define full addressable range of shader inputs.</p>

<p>Maximum texture size is 4096 by 4096 texels.</p>

<p>The number of bits per texel is 32 on mobile platforms, and 128 on laptops.
32 bits per texel comes from four R, G, B, and A channels 8 bits (0..255) each.
128 bits per texel comes from four 32-bit floating point numbers.
128 bits per texel is only available with <code>OES_texture_float</code> extension enabled.
It's available on the most but very low-end platforms.</p>

<p>Texture image units comprise primary high-bandwidth input to shader.</p>

<p>Color buffers comprise the main output. On laptops there are 8 color buffers.</p>

<p>Color buffer size varies from 4096x4096 on phones, to 16384x16384 on laptops.
Due to texture flipping technique, using those color buffers for GPGPU doesn't give
a performance advantage. The only use of the color buffer resolutions above 4096
is for actual graphical rendering of visible images, which are not intended to be
used as textures.</p>

<p>Our main goal is to do GPGPU rather than rendering graphics, so let's assume
that the maximum color buffer size is 4096 by 4096, and only bump it up for special
purposes (real-time graphics and high-resolution export).</p>

<h2>Total addressable shader input</h2>
<ul>
<li>Low-end mobile: <pre><code>8 texture units
*
4096 texels wide
*
4096 texels tall
*
4 RGBA channels
*
8 bits channel
=
4,294,967,296 bits
=
536,870,912 bytes = 512 MB.</code></pre></li>
<li>Typical mobile: <pre><code>8 texture units
*
4096 texels wide
*
4096 texels tall
*
4 RGBA channels
*
32 bits channel (float)
=
17,179,869,184 bits
=
2,147,483,648 bytes = 2 GB.</code></pre></li>
<li>A simple laptop: <pre><code>32 texture units
*
4096 texels wide
*
4096 texels tall
*
4 RGBA channels
*
32 bits channel (float)
=
68,719,476,736 bits
=
8,589,934,592 bytes = 8 GB.</code></pre></li>
</ul>

<p>High-end AMD and Nvidia GPUs allow addressing even larger texture memory.</p>

<h2>Total addressable shader output</h2>

<p>If texture unit memory is a potential access,
color buffer memory is often full write. As optimization,
we can render triangles and rectangles to only run shader
over specified block of output memory,
when we know for sure for which areas recomputation is needed</p>.
<ul>
<li>Mobile color buffer <pre><code>1 color buffer
*
4096 texels wide
*
4096 texels tall
*
4 RGBA channels
*
8 bits channel
=
536,870,912 bits
=
67,108,864 bytes = 64 MB.</code></pre>Not much per a shader run.
Note that visible mobile framebuffer often has less than 8 bits per channel,
but it's irrelevant for GPGPU computation.</li>
<li>Laptop color buffer in GPGPU mode <pre><code>8 color buffers
*
4096 texels wide
*
4096 texels tall
*
4 RGBA channels
*
32 bits channel (float)
=
17,179,869,184 bits
=
2,147,483,648 bytes = 2 GB.</code></pre></li>
<li>Laptop color buffer in graphics mode makes sense
	to output just one color buffer, despite the support of 8,
	rendering an RGB image 768 MB large (16384x16384 size).</li>
</ul>

<p>On most systems, memory bandwidth is the main limiting factor of how many bits can
be computed per second. A laptop with DDR4-2400, for example, has 18.75 GB/s.
iPhone XS Max' LPDDR4X has 8.33 GB/s.</p>
	
<h2>Code</h2>

<p>We can run many switching operations simultaneously using parallelism provided by GPU.
Let's enable WebGL API so we can issue descriptions of what to compute to the GPU:</p>

<textarea class="code">
const gl_canvas =
	document.createElement('canvas');
gl_canvas.setAttribute('width', '1px');
gl_canvas.setAttribute('height', '1px');

window.gl = gl_canvas.getContext('webgl', {
	depth: false,
	stencil: false,
	alpha: false,
	antialias: false,
	preserveDrawingBuffer: false,
	failIfMajorPerformanceCaveat: false,
	powerPreference: 'high-performance',
	desynchronized: true,
});

// this.insertAdjacentElement('afterend',
// gl_canvas);

return gl;
</textarea>

<p>The sequence of calls to get our GLSL shader compiled is rather verbose.
It follows C API, which doesn't make too much sense in JavaScript world.
Let's ignore the fact, and pack it inside a function, so we can call it each time
we need to compile a new shader:</p>

<textarea class="code">
window.compile_shader = (gl, vertSrc, fragSrc) => {

	const vertex_shader =
		gl.createShader(gl.VERTEX_SHADER);

	gl.shaderSource(vertex_shader, vertSrc);
	gl.compileShader(vertex_shader);

	const frag_shader =
		gl.createShader(gl.FRAGMENT_SHADER);

	gl.shaderSource(frag_shader, fragSrc);
	gl.compileShader(frag_shader);

	const program = gl.createProgram();
	gl.attachShader(program, vertex_shader);
	gl.attachShader(program, frag_shader);
	gl.linkProgram(program);

	if (!gl.getProgramParameter(program,
			gl.LINK_STATUS)) {
		let error_text =
			`Could not initialise shaders ${
				gl.getProgramInfoLog(program) }\n`;

		if (!gl.getShaderParameter(vertex_shader,
				gl.COMPILE_STATUS)) {
			error_text += `failed to compile vertex ${
				gl.getShaderInfoLog(vertex_shader) }\n`;
		}
		
		if (!gl.getShaderParameter(frag_shader,
				gl.COMPILE_STATUS)) {
			error_text += `failed to compile vertex ${
				gl.getShaderInfoLog(frag_shader) }\n`;
		}
		throw Error(error_text);
	}

	const compile_log = '' +
		gl.getShaderInfoLog(vertex_shader) +
		gl.getShaderInfoLog(frag_shader) +
		gl.getProgramInfoLog(program);

	if (compile_log) {
		throw Error(compile_log);
	}

	return program;
};
</textarea>


<p>Now we can call the <code>compile_shader()</code> function.
A vertex and a fragment shader source code strings are passed as arguments.
And we also pass a WebGL API reference associated with the canvas.
What happens next is OpenGL ES 2 driver compiles these two GLSL shader source codes
into a corresponding GPU instruction set.</p>


<textarea class="code">
const vertex_shader = `
#version 100

precision highp float;
attribute vec2 attr_vertex_pos;
void main() {
  gl_Position = vec4(attr_vertex_pos.xy,
  	0.0, 1.0);
}
`;

const fragment_shader = `
#version 100

# ifdef GL_FRAGMENT_PRECISION_HIGH
precision highp float;
precision highp int;
precision highp sampler2D;
# else
precision mediump float;
precision lowp int;
precision lowp sampler2D;
# endif

uniform sampler2D texture_0;

void main() {
	vec4 input_data = texture2D(
		texture_0, vec2(0.0, 0.0));

	// Just return the pixel
	gl_FragData[0] = input_data;
}
`;

window.shader =
	compile_shader(gl,
		vertex_shader,
		fragment_shader);

window.attr_vertex_pos = gl.getAttribLocation(
	shader, 'attr_vertex_pos');


window.uniform_texture_0 =
	gl.getUniformLocation(
		shader, 'texture_0');

return [shader,
	attr_vertex_pos,
	uniform_texture_0];
</textarea>

<p>Let's check out if we can write shaders which produce floating point values
rather than 4 bytes of RGBA in the range from 0 to 255.</p>

<textarea class="code">
return gl.getExtension('WEBGL_color_buffer_float');
</textarea>

<p>If it shows <em>OK</em>, then the shader can only output 4 byte values. No float rendering on this platform.</p>

<p>Perhaps, we can render simultaneously to multiple textures?</p>
<textarea class="code">
const ext_draw_buffers =
	gl.getExtension('WEBGL_draw_buffers');
return ext_draw_buffers &&
	ext_draw_buffers.MAX_COLOR_ATTACHMENTS_WEBGL
	// ext_draw_buffers.MAX_DRAW_BUFFERS_WEBGL
</textarea>

<p>Typically, mobile platforms don't support rendering to floating point textures,
and don't support rendering to multiple textures simultaneously.</p>

<p>When running a shader, can we at least fetch 4-vectors of floating point values?</p>
<textarea class="code">
return gl.getExtension('OES_texture_float');
</textarea>

<p>Let's abstract out the difference between high-performance GPU in a laptop,
and a battery-efficient GPU in a smartphone, and write a GLSL wrapper to call our shaders.</p>

<p>In the shader source code, we'll make global parameters available, so our code can adjust correspondingly.
The code might look like this:</p>

<textarea class="code">
`

void main () {
  // Location of current output pixel.
  gl_FragCoord.xy;

  vec2 screenPos = gl_FragCoord.xy - 0.5;
  float x = screenPos.x;
  float y = screenPos.y;

  float oddRow = mod(y, 2.0) > 0.0 ? 0.0 : 1.0;

  // Writing output into a plane
  // a) Smartphone mode - 32 bits per pixel:
  gl_FragData[0] = vec4(0, 255, 127, 0) / 255.0;
  // b) Laptop mode - 


`
</textarea>


<p>Let's leave high-performance rendering for special use cases, and use
the most compatible configuration (fetch from 8 floating point vec4,
but render to just 4 bytes - 32 bits of result in a shader thread).
Luckily, fetching vec4 from 4 bytes doesn't have memory tranfer penalty,
so we can move the same buffer back-and-forth while recomputing the <em>next state</em>.</p>

<p>Let's run our first GLSL shader. At first, we need to understand how to invoke a shader code.
Since GPU is a <em>graphics</em> processing unit, the traditional way is to pass a set of triangles
to toggle rendering.</p>

<p>How do we render triangles? We need a render target.
We omitted attaching our canvas to the page, so we don't have to render to the framebuffer,
but we're going to render into a <em>texture</em> instead.</p>

<p>Note that the range of output data to be recomputed is directly determined
by the <em>triangles</em> we're about to render. We can enable reactivity and lazy recomputation
of only areas which do require to get updated. In general case though, when each data output
depends on each data input, it's impossible to determine what outputs will become changed:
that's the very purpose of any computation.</p>

<p>Let's try a 1x1 pixel texture first:</p>
<textarea class="code">
window.gpgpu_texture_width = 1;
window.gpgpu_texture_height = 1;

gl.useProgram(shader);

gl.viewport(0, 0,
	gpgpu_texture_width, gpgpu_texture_height);

// Enables multiple shader texture uniforms
gl.activeTexture(gl.TEXTURE0);
gl.uniform1i(uniform_texture_0, 0);

gl.bindTexture(gl.TEXTURE_2D, gpgpu_texture_0);



gl.enableVertexAttribArray(pos_attr);
// BYTE: signed 8-bit integer, with values in [-128..127] (when normalized mapped to [-1..1] with step 0.0078125)
// SHORT: signed 16-bit integer, with values in [-32768..32767] (when normalized mapped to [-1..1] with step 0.000030517)
// UNSIGNED_BYTE: unsigned 8-bit integer, with src values in [0..255] (when normalized mapped to [0..1] with step 0.00390625)
// UNSIGNED_SHORT: unsigned 16-bit integer, with values in [0..65535] (when normalized mapped to [0..1] with step 0.000015258)
// FLOAT: 32-bit IEEE floating point number, never normalized
gl.vertexAttribPointer(pos_attr, 2, gl.FLOAT, false, 0, 0);

</textarea>

<textarea class="code">
gl.useProgram(compiled_shader);
</textarea>

</section>
</main>

<nav>
<a href="./">To First Page</a>
<a href="smth">Next</a>
</nav>

